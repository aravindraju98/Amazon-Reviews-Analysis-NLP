{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Set plotting style\n",
    "\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path):\n",
    "    \"\"\"Load and preprocess the reviews data\"\"\"\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_json(file_path, lines=True, compression='gzip')\n",
    "    \n",
    "    # Print initial info\n",
    "    print(\"\\nInitial Dataset Info:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Total number of reviews: {len(df)}\")\n",
    "    print(f\"Number of unique products: {df['asin'].nunique()}\")\n",
    "    \n",
    "    # Custom stop words specific to Kindle app reviews\n",
    "    custom_stops = {\n",
    "        'kindle', 'amazon', 'app', 'book', 'books', 'read', 'reading',\n",
    "        'reader', 'version', 'using', 'use', 'used', 'one', 'get', \n",
    "        'got', 'would', 'could', 'cant', 'cannot', 'im', 'ive',\n",
    "        'device', 'time', 'like', 'really', 'way', 'even'\n",
    "    }\n",
    "    \n",
    "    def clean_text(text):\n",
    "        \"\"\"Clean individual text by removing custom stop words\"\"\"\n",
    "        if isinstance(text, str):\n",
    "            # Convert to lowercase\n",
    "            text = text.lower()\n",
    "            # Replace custom stop words with space\n",
    "            for word in custom_stops:\n",
    "                text = text.replace(f' {word} ', ' ')\n",
    "            # Remove extra spaces\n",
    "            text = ' '.join(text.split())\n",
    "            return text\n",
    "        return ''\n",
    "    \n",
    "    # Clean reviewText\n",
    "    print(\"\\nCleaning review text...\")\n",
    "    df['reviewText'] = df['reviewText'].apply(clean_text)\n",
    "    \n",
    "    # Remove rows with empty reviews after cleaning\n",
    "    df = df.dropna(subset=['reviewText'])\n",
    "    df = df[df['reviewText'].str.strip() != '']\n",
    "    \n",
    "    # Keep essential columns\n",
    "    df = df[['asin', 'reviewText', 'overall']]\n",
    "    \n",
    "    # Get most reviewed product (Kindle app)\n",
    "    most_reviewed_asin = df['asin'].value_counts().index[0]\n",
    "    df = df[df['asin'] == most_reviewed_asin].copy()\n",
    "    \n",
    "    print(f\"\\nNumber of reviews after preprocessing: {len(df)}\")\n",
    "    \n",
    "    # Print sample of cleaned reviews\n",
    "    print(\"\\nSample of cleaned reviews:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(df['reviewText'].head())\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_sentiment_analysis(df):\n",
    "    \"\"\"Analyze sentiment of reviews\"\"\"\n",
    "    def get_sentiment(text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    \n",
    "    def categorize_sentiment(score):\n",
    "        if score > 0:\n",
    "            return 'Positive'\n",
    "        elif score < 0:\n",
    "            return 'Negative'\n",
    "        return 'Neutral'\n",
    "    \n",
    "    df['sentiment_score'] = df['reviewText'].apply(get_sentiment)\n",
    "    df['sentiment_category'] = df['sentiment_score'].apply(categorize_sentiment)\n",
    "    \n",
    "       \n",
    "    # Visualize sentiment distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sentiment_counts = df['sentiment_category'].value_counts()\n",
    "        \n",
    "    colors = {'Positive': '#2ecc71', 'Negative': '#e74c3c', 'Neutral': '#95a5a6'}\n",
    "    bars = plt.bar(sentiment_counts.index, sentiment_counts.values,\n",
    "                    color=[colors[cat] for cat in sentiment_counts.index])\n",
    "        \n",
    "        # Add percentage labels\n",
    "    total = len(df)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height/total*100:.1f}%\\n({int(height)})',\n",
    "                ha='center', va='bottom')\n",
    "        \n",
    "    plt.title('Sentiment Distribution in Kindle App Reviews', fontsize=14, pad=20)\n",
    "    plt.xlabel('Sentiment Category', fontsize=12)\n",
    "    plt.ylabel('Number of Reviews', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print sentiment statistics\n",
    "    print(\"\\nSentiment Analysis Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    for category in ['Positive', 'Negative', 'Neutral']:\n",
    "        count = sentiment_counts[category]\n",
    "        percentage = (count/total) * 100\n",
    "        avg_score = df[df['sentiment_category'] == category]['sentiment_score'].mean()\n",
    "        print(f\"{category}: {count} reviews ({percentage:.1f}%), Average score: {avg_score:.3f}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_topic_modeling(df):\n",
    "    \"\"\"Perform topic modeling on reviews\"\"\"\n",
    "    def preprocess_text(text):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        custom_stops = {'kindle', 'amazon', 'app', 'book', 'books'}\n",
    "        stop_words.update(custom_stops)\n",
    "        \n",
    "        tokens = word_tokenize(str(text).lower())\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens \n",
    "                 if word.isalpha() and word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    print(\"Preprocessing text for topic modeling...\")\n",
    "    processed_docs = df['reviewText'].apply(preprocess_text)\n",
    "    \n",
    "    # Create document-term matrix\n",
    "    vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "    doc_term_matrix = vectorizer.fit_transform(processed_docs)\n",
    "    \n",
    "    # Perform LDA\n",
    "    n_topics = 5\n",
    "    lda_model = LatentDirichletAllocation(n_components=n_topics,\n",
    "                                          random_state=42,\n",
    "                                          max_iter=100)\n",
    "    lda_output = lda_model.fit_transform(doc_term_matrix)\n",
    "    \n",
    "    return lda_model, vectorizer, lda_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_topics(lda_model, vectorizer, df):\n",
    "    \"\"\"Interpret and visualize topics\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    topic_keywords_dict = {\n",
    "        'Installation & Setup': ['download', 'install', 'version', 'window', 'computer', 'pc', 'device', 'update'],\n",
    "        'Reading Experience': ['read', 'page', 'screen', 'text', 'font', 'size', 'view', 'zoom'],\n",
    "        'Technical Performance': ['work', 'issue', 'problem', 'slow', 'crash', 'bug', 'fix', 'error'],\n",
    "        'Features & Usage': ['feature', 'use', 'easy', 'option', 'function', 'library', 'collection'],\n",
    "        'Customer Support': ['support', 'help', 'service', 'customer', 'contact', 'response', 'update']\n",
    "    }\n",
    "    \n",
    "    topic_labels = {}\n",
    "    n_words = 10\n",
    "    \n",
    "    # Plot topics\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_words_idx = topic.argsort()[:-n_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        top_weights = [topic[i] for i in top_words_idx]\n",
    "        \n",
    "        # Determine topic label\n",
    "        max_overlap = 0\n",
    "        best_label = f'Topic {topic_idx + 1}'\n",
    "        for label, keywords in topic_keywords_dict.items():\n",
    "            overlap = len(set(top_words) & set(keywords))\n",
    "            if overlap > max_overlap:\n",
    "                max_overlap = overlap\n",
    "                best_label = label\n",
    "        \n",
    "        topic_labels[topic_idx] = best_label\n",
    "        \n",
    "        # Plot topic\n",
    "        plt.subplot(3, 2, topic_idx + 1)\n",
    "        plt.bar(range(n_words), top_weights)\n",
    "        plt.xticks(range(n_words), top_words, rotation=45, ha='right')\n",
    "        plt.title(f'{best_label}', fontsize=12, pad=10)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "   \n",
    "    plt.show()\n",
    "    \n",
    "    return topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_topic_sentiment(df, topic_labels):\n",
    "    \"\"\"Analyze sentiment distribution across topics\"\"\"\n",
    "    # Calculate topic-sentiment distribution\n",
    "    topic_sentiment = pd.crosstab(df['topic_label'], df['sentiment_category'])\n",
    "    topic_sentiment_pct = topic_sentiment.div(topic_sentiment.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = {'Positive': '#2ecc71', 'Negative': '#e74c3c', 'Neutral': '#95a5a6'}\n",
    "    topic_sentiment_pct.plot(kind='bar', stacked=True,\n",
    "                            color=[colors[cat] for cat in topic_sentiment_pct.columns])\n",
    "    \n",
    "    plt.title('Sentiment Distribution Across Topics', fontsize=14, pad=20)\n",
    "    plt.xlabel('Topics', fontsize=12)\n",
    "    plt.ylabel('Percentage of Reviews', fontsize=12)\n",
    "    plt.legend(title='Sentiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"\\nTopic-Sentiment Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    for topic in topic_sentiment.index:\n",
    "        print(f\"\\n{topic}:\")\n",
    "        print(f\"Total reviews: {topic_sentiment.loc[topic].sum()}\")\n",
    "        print(\"Sentiment distribution:\")\n",
    "        for sentiment in ['Positive', 'Negative', 'Neutral']:\n",
    "            pct = topic_sentiment_pct.loc[topic, sentiment]\n",
    "            count = topic_sentiment.loc[topic, sentiment]\n",
    "            print(f\"  {sentiment}: {pct:.1f}% ({count} reviews)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordclouds(df):\n",
    "    \"\"\"Generate word clouds for different sentiment categories\"\"\"\n",
    "    for sentiment in ['Positive', 'Negative', 'Neutral']:\n",
    "        text = ' '.join(df[df['sentiment_category'] == sentiment]['reviewText'])\n",
    "        \n",
    "        wordcloud = WordCloud(width=800, height=400,\n",
    "                            background_color='white',\n",
    "                            max_words=150,\n",
    "                            contour_width=3,\n",
    "                            contour_color='steelblue').generate(text)\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Word Cloud - {sentiment} Reviews', fontsize=14, pad=20)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Load and preprocess data\n",
    "df = preprocess_data('Software.json.gz')\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Perform sentiment analysis\n",
    " df = perform_sentiment_analysis(df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Perform topic modeling\n",
    "lda_model, vectorizer, lda_output = perform_topic_modeling(df)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Interpret topics\n",
    "topic_labels = interpret_topics(lda_model, vectorizer, df)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign topics to reviews\n",
    "df['dominant_topic'] = lda_output.argmax(axis=1)\n",
    "df['topic_label'] = df['dominant_topic'].map(topic_labels)\n",
    "    \n",
    "\n",
    "\n",
    "# Analyze topic-sentiment relationship\n",
    "analyze_topic_sentiment(df, topic_labels)\n",
    "    \n",
    "    \n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word clouds\n",
    "generate_wordclouds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_key_terms(df):\n",
    "    \"\"\"\n",
    "    Analyze and visualize key terms in reviews with their sentiment context\n",
    "    \"\"\"\n",
    "    # Split reviews into words and get frequency\n",
    "    words = ' '.join(df['reviewText']).lower().split()\n",
    "    word_freq = pd.Series(words).value_counts()\n",
    "    \n",
    "    # Categorize terms\n",
    "    feature_terms = ['screen', 'interface', 'library', 'font', 'page', 'search', 'sync', 'bookmark']\n",
    "    usability_terms = ['easy', 'simple', 'intuitive', 'difficult', 'complicated', 'confusing']\n",
    "    performance_terms = ['fast', 'slow', 'crash', 'freeze', 'smooth', 'responsive']\n",
    "    quality_terms = ['great', 'excellent', 'poor', 'terrible', 'awesome', 'bad']\n",
    "    \n",
    "    categories = {\n",
    "        'Product Features': feature_terms,\n",
    "        'Usability': usability_terms,\n",
    "        'Performance': performance_terms,\n",
    "        'Quality': quality_terms\n",
    "    }\n",
    "    \n",
    "    # Create visualization for each category\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for idx, (category, terms) in enumerate(categories.items(), 1):\n",
    "        plt.subplot(2, 2, idx)\n",
    "        \n",
    "        # Get frequencies for terms in this category\n",
    "        cat_freq = word_freq[word_freq.index.isin(terms)]\n",
    "        if len(cat_freq) > 0:\n",
    "            # Sort by frequency\n",
    "            cat_freq = cat_freq.sort_values(ascending=True)\n",
    "            \n",
    "            # Create horizontal bar chart\n",
    "            bars = plt.barh(range(len(cat_freq)), cat_freq.values)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar in bars:\n",
    "                width = bar.get_width()\n",
    "                plt.text(width, bar.get_y() + bar.get_height()/2,\n",
    "                        f'{int(width):,}',\n",
    "                        ha='left', va='center', fontsize=10)\n",
    "            \n",
    "            # Customize appearance\n",
    "            plt.yticks(range(len(cat_freq)), cat_freq.index)\n",
    "            plt.title(f'{category} - Key Terms', pad=20)\n",
    "            plt.xlabel('Frequency in Reviews')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # Create summary table\n",
    "    print(\"\\nKey Terms Analysis Summary\")\n",
    "    print(\"-\" * 50)\n",
    "    for category, terms in categories.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        cat_freq = word_freq[word_freq.index.isin(terms)].sort_values(ascending=False)\n",
    "        for term, freq in cat_freq.items():\n",
    "            # Calculate percentage of reviews containing this term\n",
    "            percentage = (freq / len(df)) * 100\n",
    "            print(f\"{term}: {freq:,} mentions ({percentage:.1f}% of reviews)\")\n",
    "\n",
    "def create_sentiment_summary(df):\n",
    "    \"\"\"\n",
    "    Create a clear summary of sentiment patterns\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Calculate sentiment patterns over time\n",
    "    df['month'] = pd.to_datetime(df['reviewTime']).dt.to_period('M')\n",
    "    monthly_sentiment = df.groupby('month')['sentiment_category'].value_counts(normalize=True).unstack()\n",
    "    \n",
    "    # Create stacked area chart\n",
    "    ax = monthly_sentiment.plot(kind='area', stacked=True,\n",
    "                              color=['#2ecc71', '#95a5a6', '#e74c3c'])\n",
    "    \n",
    "    plt.title('Sentiment Trends Over Time', pad=20)\n",
    "    plt.xlabel('Time Period')\n",
    "    plt.ylabel('Proportion of Reviews')\n",
    "    plt.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def create_key_metrics_dashboard(df):\n",
    "    \"\"\"\n",
    "    Create a dashboard with key business metrics\n",
    "    \"\"\"\n",
    "    # Calculate key metrics\n",
    "    total_reviews = len(df)\n",
    "    avg_rating = df['overall'].mean()\n",
    "    sentiment_dist = df['sentiment_category'].value_counts(normalize=True)\n",
    "    \n",
    "    # Common issues mentioned\n",
    "    issue_terms = ['crash', 'bug', 'error', 'slow', 'difficult', 'confusing']\n",
    "    issue_mentions = sum(df['reviewText'].str.contains('|'.join(issue_terms), case=False))\n",
    "    \n",
    "    # Positive aspects\n",
    "    positive_terms = ['great', 'excellent', 'love', 'perfect', 'awesome']\n",
    "    positive_mentions = sum(df['reviewText'].str.contains('|'.join(positive_terms), case=False))\n",
    "    \n",
    "    # Create summary visualization\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Key metrics panel\n",
    "    plt.subplot(1, 2, 1)\n",
    "    metrics = [\n",
    "        f'Total Reviews: {total_reviews:,}',\n",
    "        f'Average Rating: {avg_rating:.1f}/5.0',\n",
    "        f'Positive Sentiment: {sentiment_dist[\"Positive\"]*100:.1f}%',\n",
    "        f'Issue Mentions: {issue_mentions:,}',\n",
    "        f'Positive Mentions: {positive_mentions:,}'\n",
    "    ]\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('Key Performance Metrics', pad=20, fontsize=14)\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        plt.text(0.1, 0.8 - (idx * 0.15), metric, fontsize=12)\n",
    "    \n",
    "    # Recommendations panel\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('off')\n",
    "    plt.title('Key Insights & Recommendations', pad=20, fontsize=14)\n",
    "    \n",
    "    recommendations = [\n",
    "        'Focus Areas:',\n",
    "        '• Performance optimization',\n",
    "        '• User interface simplification',\n",
    "        '• Feature enhancement',\n",
    "        'Success Metrics:',\n",
    "        '• User satisfaction trending up',\n",
    "        '• Decreased error reports'\n",
    "    ]\n",
    "    \n",
    "    for idx, rec in enumerate(recommendations):\n",
    "        plt.text(0.1, 0.8 - (idx * 0.1), rec, fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Use all visualizations\n",
    "def create_business_analysis(df):\n",
    "    analyze_key_terms(df)\n",
    "    create_sentiment_summary(df)\n",
    "    create_key_metrics_dashboard(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_key_terms(df):\n",
    "    \"\"\"\n",
    "    Analyze and visualize key terms in reviews with their sentiment context\n",
    "    \"\"\"\n",
    "    # Split reviews into words and get frequency\n",
    "    words = ' '.join(df['reviewText']).lower().split()\n",
    "    word_freq = pd.Series(words).value_counts()\n",
    "    \n",
    "    # Categorize terms\n",
    "    feature_terms = ['screen', 'interface', 'library', 'font', 'page', 'search', 'sync', 'bookmark']\n",
    "    usability_terms = ['easy', 'simple', 'intuitive', 'difficult', 'complicated', 'confusing']\n",
    "    performance_terms = ['fast', 'slow', 'crash', 'freeze', 'smooth', 'responsive']\n",
    "    quality_terms = ['great', 'excellent', 'poor', 'terrible', 'awesome', 'bad']\n",
    "    \n",
    "    categories = {\n",
    "        'Product Features': feature_terms,\n",
    "        'Usability': usability_terms,\n",
    "        'Performance': performance_terms,\n",
    "        'Quality': quality_terms\n",
    "    }\n",
    "    \n",
    "    # Create visualization for each category\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for idx, (category, terms) in enumerate(categories.items(), 1):\n",
    "        plt.subplot(2, 2, idx)\n",
    "        \n",
    "        # Get frequencies for terms in this category\n",
    "        cat_freq = word_freq[word_freq.index.isin(terms)]\n",
    "        if len(cat_freq) > 0:\n",
    "            # Sort by frequency\n",
    "            cat_freq = cat_freq.sort_values(ascending=True)\n",
    "            \n",
    "            # Create horizontal bar chart with custom colors\n",
    "            bars = plt.barh(range(len(cat_freq)), cat_freq.values, \n",
    "                          color=plt.cm.Blues(np.linspace(0.3, 0.9, len(cat_freq))))\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar in bars:\n",
    "                width = bar.get_width()\n",
    "                plt.text(width, bar.get_y() + bar.get_height()/2,\n",
    "                        f'{int(width):,}',\n",
    "                        ha='left', va='center', fontsize=10,\n",
    "                        bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "            \n",
    "            # Customize appearance\n",
    "            plt.yticks(range(len(cat_freq)), cat_freq.index)\n",
    "            plt.title(f'{category} - Mentioned in Reviews', pad=20, fontsize=12)\n",
    "            plt.xlabel('Number of Mentions')\n",
    "            plt.grid(True, alpha=0.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary table\n",
    "    print(\"\\nKey Terms Analysis Summary\")\n",
    "    print(\"-\" * 50)\n",
    "    for category, terms in categories.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        cat_freq = word_freq[word_freq.index.isin(terms)].sort_values(ascending=False)\n",
    "        if len(cat_freq) > 0:\n",
    "            for term, freq in cat_freq.items():\n",
    "                percentage = (freq / len(df)) * 100\n",
    "                print(f\"{term}: {freq:,} mentions ({percentage:.1f}% of reviews)\")\n",
    "\n",
    "def create_key_metrics_dashboard(df):\n",
    "    \"\"\"\n",
    "    Create a dashboard with key business metrics\n",
    "    \"\"\"\n",
    "    # Calculate key metrics\n",
    "    total_reviews = len(df)\n",
    "    avg_rating = df['overall'].mean()\n",
    "    \n",
    "    # Calculate sentiment distribution\n",
    "    sentiment_dist = df['sentiment_category'].value_counts()\n",
    "    sentiment_pct = sentiment_dist / len(df) * 100\n",
    "    \n",
    "    # Common issues and positive aspects\n",
    "    issue_terms = ['crash', 'bug', 'error', 'slow', 'difficult', 'confusing']\n",
    "    positive_terms = ['great', 'excellent', 'love', 'perfect', 'awesome']\n",
    "    \n",
    "    issue_counts = {term: len(df[df['reviewText'].str.contains(term, case=False)]) \n",
    "                   for term in issue_terms}\n",
    "    positive_counts = {term: len(df[df['reviewText'].str.contains(term, case=False)]) \n",
    "                      for term in positive_terms}\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # 1. Sentiment Distribution Pie Chart\n",
    "    plt.subplot(1, 3, 1)\n",
    "    colors = {'Positive': '#2ecc71', 'Negative': '#e74c3c', 'Neutral': '#95a5a6'}\n",
    "    plt.pie(sentiment_pct, labels=[f'{cat}\\n{pct:.1f}%' \n",
    "            for cat, pct in zip(sentiment_dist.index, sentiment_pct)],\n",
    "            colors=[colors[cat] for cat in sentiment_dist.index],\n",
    "            autopct='',\n",
    "            startangle=90)\n",
    "    plt.title('Sentiment Distribution', pad=20)\n",
    "    \n",
    "    # 2. Common Issues Bar Chart\n",
    "    plt.subplot(1, 3, 2)\n",
    "    issue_data = pd.Series(issue_counts).sort_values(ascending=True)\n",
    "    bars = plt.barh(range(len(issue_data)), issue_data.values, \n",
    "                   color=plt.cm.Reds(np.linspace(0.3, 0.7, len(issue_data))))\n",
    "    plt.yticks(range(len(issue_data)), issue_data.index)\n",
    "    plt.title('Common Issues Mentioned', pad=20)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width, bar.get_y() + bar.get_height()/2,\n",
    "                f'{int(width):,}',\n",
    "                ha='left', va='center')\n",
    "    \n",
    "    # 3. Positive Aspects Bar Chart\n",
    "    plt.subplot(1, 3, 3)\n",
    "    positive_data = pd.Series(positive_counts).sort_values(ascending=True)\n",
    "    bars = plt.barh(range(len(positive_data)), positive_data.values,\n",
    "                    color=plt.cm.Greens(np.linspace(0.3, 0.7, len(positive_data))))\n",
    "    plt.yticks(range(len(positive_data)), positive_data.index)\n",
    "    plt.title('Positive Aspects Mentioned', pad=20)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width, bar.get_y() + bar.get_height()/2,\n",
    "                f'{int(width):,}',\n",
    "                ha='left', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nKey Business Metrics Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Total Reviews Analyzed: {total_reviews:,}\")\n",
    "    print(f\"Average Rating: {avg_rating:.2f}/5.0\")\n",
    "    print(\"\\nSentiment Distribution:\")\n",
    "    for cat, pct in sentiment_pct.items():\n",
    "        print(f\"{cat}: {pct:.1f}%\")\n",
    "\n",
    "# Function to run all analyses\n",
    "def run_business_analysis(df):\n",
    "    print(\"Business Analysis of Kindle App Reviews\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Run analyses\n",
    "    analyze_key_terms(df)\n",
    "    create_key_metrics_dashboard(df)\n",
    "    \n",
    "    # Print recommendations\n",
    "    print(\"\\nKey Recommendations:\")\n",
    "    print(\"-\" * 50)\n",
    "    positive_ratio = len(df[df['sentiment_category'] == 'Positive']) / len(df)\n",
    "    \n",
    "    if positive_ratio < 0.6:\n",
    "        print(\"1. Focus on improving overall user satisfaction:\")\n",
    "        print(\"   - Address common issues in user feedback\")\n",
    "        print(\"   - Enhance features that receive positive mentions\")\n",
    "    \n",
    "    print(\"2. Priority Areas for Improvement:\")\n",
    "    print(\"   - Technical Performance: Address crash reports and speed issues\")\n",
    "    print(\"   - User Interface: Simplify complex features\")\n",
    "    print(\"   - Feature Enhancement: Focus on most requested features\")\n",
    "    \n",
    "    print(\"\\n3. Success Metrics to Track:\")\n",
    "    print(\"   - User satisfaction trends\")\n",
    "    print(\"   - Issue report frequency\")\n",
    "    print(\"   - Feature usage statistics\")\n",
    "\n",
    "# Use the analysis\n",
    "run_business_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
